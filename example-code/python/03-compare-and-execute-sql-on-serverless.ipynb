{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this script to compare and  execute all database objects on the synapse serverless sql server\n",
    "import sys\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "sys.path.insert(0, r\"examplecode\\python\\functions\")\n",
    "from functions.sqlauth import *\n",
    "from functions.synserverlessobjects import *\n",
    "from functions.dataframeoperations import *\n",
    "\n",
    "server = 'target-synapse-server-ondemand.sql.azuresynapse.net'\n",
    "\n",
    "#get local settings\n",
    "username, repo_path = get_personal_settings()\n",
    "base_wd = 'C:\\\\Users\\\\Arthur.Steijn\\\\source\\\\repos\\\\synapse-serverless-sql-cicd-python\\\\synapse-serverless-objects\\\\'\n",
    "\n",
    "\n",
    "environment_reference_d = 'development-server'\n",
    "environment_reference_p = 'production-server'\n",
    "\n",
    "# set to variable to true, to execute statements on server\n",
    "execute_var = 'False'\n",
    "\n",
    "def main():\n",
    "    \"\"\" Function to connect to an azure synapse ondemand server \n",
    "        and execute all views, stored procedures and functions on their databases \"\"\"\n",
    "    \n",
    "    #authenticate to the server with azure ad account\n",
    "    print('Creata a connection and cursor to the synapse server')\n",
    "    cursor, cnxn =  dbcnxn(server, username)\n",
    "   \n",
    "    #create df from repo\n",
    "    print('Create dataframe from repo scripts. Folder is set to: ' + repo_path)\n",
    "    df_repo = create_df_from_repo(repo_path, base_wd, localind='True')\n",
    "    print(df_repo)\n",
    "    \n",
    "    #get all databases on server\n",
    "    print('Get all databases from the server, current databases are: ')   \n",
    "    databases = get_databases(cursor)\n",
    "    for row in databases:\n",
    "        print(row[0])\n",
    "\n",
    "    #get all queries\n",
    "    print('Get queries to export synapseserver objects to a dataframe: ')   \n",
    "    sql_views, sql_sps, sql_fn = get_queries()\n",
    "\n",
    "    #get all objects from server\n",
    "    df_target = pd.DataFrame()\n",
    "    for row in databases:\n",
    "        database = row[0]\n",
    "        if 'demo_db' not in database:\n",
    "            df_views = create_target_df(sql_views, cnxn, cursor, database, 'VIEW')\n",
    "            df_target = df_target.append(df_views)\n",
    "            df_sps = create_target_df(sql_sps, cnxn, cursor, database, 'PROCEDURE')\n",
    "            df_target = df_target.append(df_sps)\n",
    "            df_fns = create_target_df(sql_fn, cnxn, cursor, database, 'FUNCTION')\n",
    "            df_target = df_target.append(df_fns)\n",
    "\n",
    "    #clean target dataframe\n",
    "    df_target['definition'] = df_target['definition'].transform(clean_sql_func_df)\n",
    "    df_target['Env'] = \"target\" \n",
    "\n",
    "    print(df_repo.columns)\n",
    "    print(df_target.columns)\n",
    "\n",
    "    #merge data frames\n",
    "    print('Prepare and Clean dataframe')\n",
    "    df_merged = merge_dataframes(df_repo, df_target)\n",
    "    df_prepared = clean_and_prepare(df_merged)\n",
    "\n",
    "    print(df_prepared)\n",
    " \n",
    "    #For Checking Purposes we create a csv that we can publish in the pipeline\n",
    "    filename = 'prepared_df'+dt.now().strftime(\"%Y%m%d_%H%M%S\")+'.txt'\n",
    "    with open(filename, 'w', newline='') as f:\n",
    "        df_prepared.to_csv(f, sep='|')\n",
    "\n",
    "    filename = 'merged_df'+dt.now().strftime(\"%Y%m%d_%H%M%S\")+'.txt'\n",
    "    with open(filename, 'w', newline='') as f:\n",
    "        df_merged.to_csv(f, sep='|')\n",
    "\n",
    "    print('execute_var is set to: ' + execute_var)\n",
    "    if(execute_var == 'True'):\n",
    "        \n",
    "        for index, row in df_prepared.iterrows():\n",
    "            database = row['DBName']\n",
    "            statement =  row['Execute_Statement']\n",
    "            schemaname = row['SchemaName']\n",
    "            objectname = row['ObjectName']\n",
    "            print('index:' + str(index) +' Executing for: '+ database +'.'+ schemaname +'.'+ objectname)\n",
    "            execute_statement(cursor, database, statement)\n",
    "    else:\n",
    "        print('no database executions')\n",
    "\n",
    "    # close connection\n",
    "    cnxn.commit()\n",
    "    cursor.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "faa63f6ad121317745b456fffd8231c4e9aebf7ca3f005e22bd1745675f0dae7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
